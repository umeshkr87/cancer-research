#!/bin/bash
#SBATCH --job-name=cancer_data_audit
#SBATCH --partition=IllinoisComputes
#SBATCH --account=aa107-ic
#SBATCH --nodes=1
#SBATCH --ntasks-per-node=1
#SBATCH --cpus-per-task=8
#SBATCH --mem=32G
#SBATCH --time=02:00:00
#SBATCH --output=/u/aa107/uiuc-cancer-research/scripts/validation/audit_%j.out
#SBATCH --error=/u/aa107/uiuc-cancer-research/scripts/validation/audit_%j.err

# =============================================================================
# PROSTATE CANCER DATA QUALITY AUDIT RUNNER - VCF MODE
# Phase 1: Comprehensive Column Analysis
# =============================================================================

set -euo pipefail  # Exit on error, undefined vars, pipe failures

echo "üß¨ PROSTATE CANCER DATA QUALITY AUDIT"
echo "Phase 1: Comprehensive Column Analysis"
echo "======================================"
echo "Job ID: $SLURM_JOB_ID"
echo "Node: $SLURMD_NODENAME"
echo "Start time: $(date)"
echo ""

# =============================================================================
# ENVIRONMENT SETUP
# =============================================================================

echo "üîß SETTING UP ENVIRONMENT"
echo "========================="

# Set project root
export PROJECT_ROOT="/u/aa107/uiuc-cancer-research"
cd $PROJECT_ROOT

# Create validation scripts directory
VALIDATION_DIR="$PROJECT_ROOT/scripts/validation"
mkdir -p $VALIDATION_DIR

# Create results directory
RESULTS_DIR="$PROJECT_ROOT/results/validation/phase1_audit"
mkdir -p $RESULTS_DIR

echo "‚úÖ Project root: $PROJECT_ROOT"
echo "‚úÖ Validation directory: $VALIDATION_DIR"
echo "‚úÖ Results directory: $RESULTS_DIR"

# =============================================================================
# DEPENDENCY CHECK
# =============================================================================

echo ""
echo "üìã CHECKING DEPENDENCIES"
echo "========================"

# Load required modules
module load anaconda3

# Initialize conda for bash (required for compute nodes)
echo "Initializing conda..."
eval "$(conda shell.bash hook)"

# Activate conda environment (create if doesn't exist)
CONDA_ENV="tabnet-prostate"
if conda info --envs | grep -q $CONDA_ENV; then
    echo "‚úÖ Activating existing environment: $CONDA_ENV"
    conda activate $CONDA_ENV
else
    echo "üî® Creating new conda environment: $CONDA_ENV"
    conda create -y -n $CONDA_ENV python=3.9
    conda activate $CONDA_ENV
fi

# Install required packages
echo "üì¶ Installing/updating Python packages..."
pip install --upgrade pip
pip install pandas numpy matplotlib seaborn scikit-learn
pip install jupyter notebook ipywidgets
pip install openpyxl xlsxwriter  # For Excel file handling

# Verify environment activation
echo "‚úÖ Environment verification:"
echo "  Python location: $(which python)"
echo "  Python version: $(python --version)"
echo "  Conda environment: $CONDA_DEFAULT_ENV"

# =============================================================================
# FILE VALIDATION - VCF MODE
# =============================================================================

echo ""
echo "üìÅ VALIDATING INPUT FILES - VCF MODE"
echo "===================================="

# Define file paths - VCF as primary input
VCF_FILE="$PROJECT_ROOT/data/processed/vep/vep_annotated_clean.vcf"
ENHANCED_FILE="$PROJECT_ROOT/data/processed/tabnet_csv/prostate_variants_tabnet_enhanced.csv"

# Check VCF file (primary input)
if [ -f "$VCF_FILE" ]; then
    FILE_SIZE=$(du -sh "$VCF_FILE" | cut -f1)
    ROW_COUNT=$(grep -v "^#" "$VCF_FILE" | wc -l)
    echo "‚úÖ VCF file found: $FILE_SIZE, $ROW_COUNT variants"
    
    # Validate VCF structure
    if grep -q "##INFO=<ID=CSQ" "$VCF_FILE"; then
        echo "‚úÖ CSQ header found in VCF"
        CSQ_FIELDS=$(grep "##INFO=<ID=CSQ" "$VCF_FILE" | grep -o "Format: [^\"]*" | cut -d: -f2- | tr '|' '\n' | wc -l)
        echo "‚úÖ CSQ fields detected: $CSQ_FIELDS"
    else
        echo "‚ùå ERROR: No CSQ header found in VCF file"
        exit 1
    fi
    
    # Check for actual CSQ annotations
    CSQ_COUNT=$(grep -v "^#" "$VCF_FILE" | head -1000 | grep -c "CSQ=" 2>/dev/null || echo "0")
    if [ "$CSQ_COUNT" -gt 0 ]; then
        echo "‚úÖ CSQ annotations found in VCF data"
    else
        echo "‚ùå ERROR: No CSQ annotations found in VCF data"
        exit 1
    fi
else
    echo "‚ùå ERROR: VCF file not found: $VCF_FILE"
    echo "üí° This file should be generated by VEP annotation pipeline"
    exit 1
fi

# Check enhanced CSV file (for comparison/fallback)
if [ -f "$ENHANCED_FILE" ]; then
    FILE_SIZE=$(du -sh "$ENHANCED_FILE" | cut -f1)
    ROW_COUNT=$(wc -l < "$ENHANCED_FILE")
    echo "‚úÖ Enhanced CSV found: $FILE_SIZE, $((ROW_COUNT-1)) variants (for comparison)"
else
    echo "‚ö†Ô∏è  Enhanced CSV not found (VCF-only analysis mode)"
fi

# =============================================================================
# CREATE AUDIT SCRIPT
# =============================================================================

echo ""
echo "üìù VALIDATING AUDIT SCRIPT"
echo "=========================="

# Verify the comprehensive audit script exists
AUDIT_SCRIPT="$VALIDATION_DIR/comprehensive_column_audit.py"

if [ ! -f "$AUDIT_SCRIPT" ]; then
    echo "‚ùå ERROR: Audit script not found. Please ensure comprehensive_column_audit.py is in:"
    echo "   $VALIDATION_DIR/"
    exit 1
else
    echo "‚úÖ Audit script found: $AUDIT_SCRIPT"
fi

# Make script executable
chmod +x "$AUDIT_SCRIPT"

# =============================================================================
# SYSTEM RESOURCE CHECK
# =============================================================================

echo ""
echo "üíª SYSTEM RESOURCE CHECK"
echo "========================"

echo "Available CPU cores: $(nproc)"
echo "Available memory: $(free -h | grep '^Mem:' | awk '{print $2}')"
echo "Available disk space: $(df -h $PROJECT_ROOT | tail -1 | awk '{print $4}')"

# Check memory requirements for VCF processing
VCF_SIZE_MB=$(du -m "$VCF_FILE" | cut -f1)
ESTIMATED_MEMORY_MB=$((VCF_SIZE_MB * 3))  # Estimate 3x file size for VCF processing

echo "VCF file size: ${VCF_SIZE_MB}MB"
echo "Estimated memory needed: ${ESTIMATED_MEMORY_MB}MB"

if [ $ESTIMATED_MEMORY_MB -gt 25000 ]; then
    echo "‚ö†Ô∏è  Large VCF file detected. Processing may take significant time."
fi

# =============================================================================
# RUN COMPREHENSIVE AUDIT - VCF MODE
# =============================================================================

echo ""
echo "üöÄ RUNNING COMPREHENSIVE DATA QUALITY AUDIT - VCF MODE"
echo "======================================================"

# Set Python path
export PYTHONPATH="$PROJECT_ROOT:${PYTHONPATH:-}"

# Run the audit with VCF input and error handling
echo "Starting VCF audit execution..."
START_TIME=$(date +%s)

# Pass VCF file path and mode to Python script
export VCF_INPUT_FILE="$VCF_FILE"
export ENHANCED_CSV_FILE="$ENHANCED_FILE"
export ANALYSIS_MODE="VCF"

if python "$AUDIT_SCRIPT"; then
    END_TIME=$(date +%s)
    DURATION=$((END_TIME - START_TIME))
    echo ""
    echo "‚úÖ AUDIT COMPLETED SUCCESSFULLY!"
    echo "Execution time: ${DURATION} seconds"
    AUDIT_STATUS="SUCCESS"
else
    END_TIME=$(date +%s)
    DURATION=$((END_TIME - START_TIME))
    echo ""
    echo "‚ùå AUDIT FAILED!"
    echo "Execution time: ${DURATION} seconds"
    echo "Check error logs for details."
    AUDIT_STATUS="FAILED"
fi

# =============================================================================
# RESULTS VALIDATION
# =============================================================================

echo ""
echo "üìä VALIDATING RESULTS"
echo "===================="

# Check if output files were generated
JSON_RESULT="$RESULTS_DIR/comprehensive_audit_results.json"
REPORT_RESULT="$RESULTS_DIR/data_quality_audit_report.txt"
CSV_RESULT="$RESULTS_DIR/column_summary.csv"

RESULTS_GENERATED=0

if [ -f "$JSON_RESULT" ]; then
    FILE_SIZE=$(du -sh "$JSON_RESULT" | cut -f1)
    echo "‚úÖ JSON results: $FILE_SIZE"
    RESULTS_GENERATED=$((RESULTS_GENERATED + 1))
else
    echo "‚ùå JSON results not generated"
fi

if [ -f "$REPORT_RESULT" ]; then
    FILE_SIZE=$(du -sh "$REPORT_RESULT" | cut -f1)
    echo "‚úÖ Text report: $FILE_SIZE"
    RESULTS_GENERATED=$((RESULTS_GENERATED + 1))
else
    echo "‚ùå Text report not generated"
fi

if [ -f "$CSV_RESULT" ]; then
    FILE_SIZE=$(du -sh "$CSV_RESULT" | cut -f1)
    echo "‚úÖ CSV summary: $FILE_SIZE"
    RESULTS_GENERATED=$((RESULTS_GENERATED + 1))
else
    echo "‚ùå CSV summary not generated"
fi

# =============================================================================
# GENERATE EXECUTION SUMMARY
# =============================================================================

echo ""
echo "üìã GENERATING EXECUTION SUMMARY"
echo "==============================="

SUMMARY_FILE="$RESULTS_DIR/audit_execution_summary.txt"

cat > "$SUMMARY_FILE" << EOF
PROSTATE CANCER DATA QUALITY AUDIT - EXECUTION SUMMARY (VCF MODE)
================================================================

Job Information:
- Job ID: $SLURM_JOB_ID
- Node: $SLURMD_NODENAME
- Start Time: $(date)
- Execution Duration: ${DURATION} seconds
- Status: $AUDIT_STATUS
- Analysis Mode: VCF

Input Files:
- VCF File: $VCF_FILE
- VCF File Size: $(du -sh "$VCF_FILE" | cut -f1)
- VCF Variants: $(grep -v "^#" "$VCF_FILE" | wc -l)
- CSQ Fields: $CSQ_FIELDS

Output Files Generated: $RESULTS_GENERATED/3
- JSON Results: $([ -f "$JSON_RESULT" ] && echo "‚úÖ" || echo "‚ùå")
- Text Report: $([ -f "$REPORT_RESULT" ] && echo "‚úÖ" || echo "‚ùå")
- CSV Summary: $([ -f "$CSV_RESULT" ] && echo "‚úÖ" || echo "‚ùå")

Environment:
- Python Version: $(python --version)
- Conda Environment: $CONDA_ENV
- Project Root: $PROJECT_ROOT

Next Steps:
1. Review generated reports in: $RESULTS_DIR
2. Analyze VCF-level concatenation patterns
3. Compare with CSV conversion results
4. Implement VEP parameter fixes if needed

Contact: aa107@illinois.edu
EOF

echo "üìÑ Execution summary saved: $SUMMARY_FILE"

# =============================================================================
# FINAL STATUS AND RECOMMENDATIONS
# =============================================================================

echo ""
echo "üéØ FINAL STATUS"
echo "==============="

if [ "$AUDIT_STATUS" = "SUCCESS" ] && [ $RESULTS_GENERATED -eq 3 ]; then
    echo "‚úÖ SUCCESS! VCF AUDIT COMPLETED!"
    echo ""
    echo "üìä Key deliverables generated:"
    echo "   - VCF CSQ field analysis"
    echo "   - Concatenation pattern identification"
    echo "   - VEP annotation quality assessment"
    echo "   - Clinical relevance scoring"
    echo "   - Pipeline source attribution"
    echo ""
    echo "üîç Next actions:"
    echo "   1. Review VCF report: $REPORT_RESULT"
    echo "   2. Analyze CSQ summary: $CSV_RESULT"
    echo "   3. Compare with CSV conversion pipeline"
    echo "   4. Implement fixes if concatenation detected"
    echo ""
    echo "üìÅ All results in: $RESULTS_DIR"
    
elif [ "$AUDIT_STATUS" = "SUCCESS" ]; then
    echo "‚ö†Ô∏è  AUDIT COMPLETED WITH ISSUES"
    echo "Some output files were not generated. Check logs for details."
    echo "üìÅ Partial results in: $RESULTS_DIR"
    
else
    echo "‚ùå AUDIT FAILED"
    echo "Check error logs and fix issues before rerunning."
    echo ""
    echo "üí° Common issues:"
    echo "   - VCF file corruption or missing CSQ headers"
    echo "   - Insufficient memory for large VCF processing"
    echo "   - Python package conflicts"
    echo "   - File permission issues"
    echo ""
    echo "üìû Support: aa107@illinois.edu"
fi

echo ""
echo "üïê End time: $(date)"
echo ""

# Set exit code based on audit status
if [ "$AUDIT_STATUS" = "SUCCESS" ] && [ $RESULTS_GENERATED -eq 3 ]; then
    exit 0
else
    exit 1
fi